{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#Importing important modules\r\n",
    "import numpy as np \r\n",
    "import pandas as pd\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#Loading data\r\n",
    "play_train = pd.read_csv(\"train.csv\")\r\n",
    "play_test = pd.read_csv(\"test.csv\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#Shape of the data\r\n",
    "print(play_train.shape)\r\n",
    "print(play_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(957919, 120)\n",
      "(493474, 119)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#Glimpse of the training data\r\n",
    "play_train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f110</th>\n",
       "      <th>f111</th>\n",
       "      <th>f112</th>\n",
       "      <th>f113</th>\n",
       "      <th>f114</th>\n",
       "      <th>f115</th>\n",
       "      <th>f116</th>\n",
       "      <th>f117</th>\n",
       "      <th>f118</th>\n",
       "      <th>claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.10859</td>\n",
       "      <td>0.004314</td>\n",
       "      <td>-37.566</td>\n",
       "      <td>0.017364</td>\n",
       "      <td>0.28915</td>\n",
       "      <td>-10.25100</td>\n",
       "      <td>135.12</td>\n",
       "      <td>168900.0</td>\n",
       "      <td>3.992400e+14</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.2280</td>\n",
       "      <td>1.7482</td>\n",
       "      <td>1.90960</td>\n",
       "      <td>-7.11570</td>\n",
       "      <td>4378.80</td>\n",
       "      <td>1.2096</td>\n",
       "      <td>8.613400e+14</td>\n",
       "      <td>140.1</td>\n",
       "      <td>1.01770</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10090</td>\n",
       "      <td>0.299610</td>\n",
       "      <td>11822.000</td>\n",
       "      <td>0.276500</td>\n",
       "      <td>0.45970</td>\n",
       "      <td>-0.83733</td>\n",
       "      <td>1721.90</td>\n",
       "      <td>119810.0</td>\n",
       "      <td>3.874100e+15</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.7580</td>\n",
       "      <td>4.1684</td>\n",
       "      <td>0.34808</td>\n",
       "      <td>4.14200</td>\n",
       "      <td>913.23</td>\n",
       "      <td>1.2464</td>\n",
       "      <td>7.575100e+15</td>\n",
       "      <td>1861.0</td>\n",
       "      <td>0.28359</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.17803</td>\n",
       "      <td>-0.006980</td>\n",
       "      <td>907.270</td>\n",
       "      <td>0.272140</td>\n",
       "      <td>0.45948</td>\n",
       "      <td>0.17327</td>\n",
       "      <td>2298.00</td>\n",
       "      <td>360650.0</td>\n",
       "      <td>1.224500e+13</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.7688</td>\n",
       "      <td>1.2042</td>\n",
       "      <td>0.26290</td>\n",
       "      <td>8.13120</td>\n",
       "      <td>45119.00</td>\n",
       "      <td>1.1764</td>\n",
       "      <td>3.218100e+14</td>\n",
       "      <td>3838.2</td>\n",
       "      <td>0.40690</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.15236</td>\n",
       "      <td>0.007259</td>\n",
       "      <td>780.100</td>\n",
       "      <td>0.025179</td>\n",
       "      <td>0.51947</td>\n",
       "      <td>7.49140</td>\n",
       "      <td>112.51</td>\n",
       "      <td>259490.0</td>\n",
       "      <td>7.781400e+13</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.8580</td>\n",
       "      <td>2.0694</td>\n",
       "      <td>0.79631</td>\n",
       "      <td>-16.33600</td>\n",
       "      <td>4952.40</td>\n",
       "      <td>1.1784</td>\n",
       "      <td>4.533000e+12</td>\n",
       "      <td>4889.1</td>\n",
       "      <td>0.51486</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.11623</td>\n",
       "      <td>0.502900</td>\n",
       "      <td>-109.150</td>\n",
       "      <td>0.297910</td>\n",
       "      <td>0.34490</td>\n",
       "      <td>-0.40932</td>\n",
       "      <td>2538.90</td>\n",
       "      <td>65332.0</td>\n",
       "      <td>1.907200e+15</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.6410</td>\n",
       "      <td>1.5298</td>\n",
       "      <td>1.14640</td>\n",
       "      <td>-0.43124</td>\n",
       "      <td>3856.50</td>\n",
       "      <td>1.4830</td>\n",
       "      <td>-8.991300e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.23049</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       f1        f2         f3        f4       f5        f6       f7  \\\n",
       "0   0  0.10859  0.004314    -37.566  0.017364  0.28915 -10.25100   135.12   \n",
       "1   1  0.10090  0.299610  11822.000  0.276500  0.45970  -0.83733  1721.90   \n",
       "2   2  0.17803 -0.006980    907.270  0.272140  0.45948   0.17327  2298.00   \n",
       "3   3  0.15236  0.007259    780.100  0.025179  0.51947   7.49140   112.51   \n",
       "4   4  0.11623  0.502900   -109.150  0.297910  0.34490  -0.40932  2538.90   \n",
       "\n",
       "         f8            f9  ...     f110    f111     f112      f113      f114  \\\n",
       "0  168900.0  3.992400e+14  ... -12.2280  1.7482  1.90960  -7.11570   4378.80   \n",
       "1  119810.0  3.874100e+15  ... -56.7580  4.1684  0.34808   4.14200    913.23   \n",
       "2  360650.0  1.224500e+13  ...  -5.7688  1.2042  0.26290   8.13120  45119.00   \n",
       "3  259490.0  7.781400e+13  ... -34.8580  2.0694  0.79631 -16.33600   4952.40   \n",
       "4   65332.0  1.907200e+15  ... -13.6410  1.5298  1.14640  -0.43124   3856.50   \n",
       "\n",
       "     f115          f116    f117     f118  claim  \n",
       "0  1.2096  8.613400e+14   140.1  1.01770      1  \n",
       "1  1.2464  7.575100e+15  1861.0  0.28359      0  \n",
       "2  1.1764  3.218100e+14  3838.2  0.40690      1  \n",
       "3  1.1784  4.533000e+12  4889.1  0.51486      1  \n",
       "4  1.4830 -8.991300e+12     NaN  0.23049      1  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "play_train.info(verbose  = True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 957919 entries, 0 to 957918\n",
      "Data columns (total 120 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   id      int64  \n",
      " 1   f1      float64\n",
      " 2   f2      float64\n",
      " 3   f3      float64\n",
      " 4   f4      float64\n",
      " 5   f5      float64\n",
      " 6   f6      float64\n",
      " 7   f7      float64\n",
      " 8   f8      float64\n",
      " 9   f9      float64\n",
      " 10  f10     float64\n",
      " 11  f11     float64\n",
      " 12  f12     float64\n",
      " 13  f13     float64\n",
      " 14  f14     float64\n",
      " 15  f15     float64\n",
      " 16  f16     float64\n",
      " 17  f17     float64\n",
      " 18  f18     float64\n",
      " 19  f19     float64\n",
      " 20  f20     float64\n",
      " 21  f21     float64\n",
      " 22  f22     float64\n",
      " 23  f23     float64\n",
      " 24  f24     float64\n",
      " 25  f25     float64\n",
      " 26  f26     float64\n",
      " 27  f27     float64\n",
      " 28  f28     float64\n",
      " 29  f29     float64\n",
      " 30  f30     float64\n",
      " 31  f31     float64\n",
      " 32  f32     float64\n",
      " 33  f33     float64\n",
      " 34  f34     float64\n",
      " 35  f35     float64\n",
      " 36  f36     float64\n",
      " 37  f37     float64\n",
      " 38  f38     float64\n",
      " 39  f39     float64\n",
      " 40  f40     float64\n",
      " 41  f41     float64\n",
      " 42  f42     float64\n",
      " 43  f43     float64\n",
      " 44  f44     float64\n",
      " 45  f45     float64\n",
      " 46  f46     float64\n",
      " 47  f47     float64\n",
      " 48  f48     float64\n",
      " 49  f49     float64\n",
      " 50  f50     float64\n",
      " 51  f51     float64\n",
      " 52  f52     float64\n",
      " 53  f53     float64\n",
      " 54  f54     float64\n",
      " 55  f55     float64\n",
      " 56  f56     float64\n",
      " 57  f57     float64\n",
      " 58  f58     float64\n",
      " 59  f59     float64\n",
      " 60  f60     float64\n",
      " 61  f61     float64\n",
      " 62  f62     float64\n",
      " 63  f63     float64\n",
      " 64  f64     float64\n",
      " 65  f65     float64\n",
      " 66  f66     float64\n",
      " 67  f67     float64\n",
      " 68  f68     float64\n",
      " 69  f69     float64\n",
      " 70  f70     float64\n",
      " 71  f71     float64\n",
      " 72  f72     float64\n",
      " 73  f73     float64\n",
      " 74  f74     float64\n",
      " 75  f75     float64\n",
      " 76  f76     float64\n",
      " 77  f77     float64\n",
      " 78  f78     float64\n",
      " 79  f79     float64\n",
      " 80  f80     float64\n",
      " 81  f81     float64\n",
      " 82  f82     float64\n",
      " 83  f83     float64\n",
      " 84  f84     float64\n",
      " 85  f85     float64\n",
      " 86  f86     float64\n",
      " 87  f87     float64\n",
      " 88  f88     float64\n",
      " 89  f89     float64\n",
      " 90  f90     float64\n",
      " 91  f91     float64\n",
      " 92  f92     float64\n",
      " 93  f93     float64\n",
      " 94  f94     float64\n",
      " 95  f95     float64\n",
      " 96  f96     float64\n",
      " 97  f97     float64\n",
      " 98  f98     float64\n",
      " 99  f99     float64\n",
      " 100 f100    float64\n",
      " 101 f101    float64\n",
      " 102 f102    float64\n",
      " 103 f103    float64\n",
      " 104 f104    float64\n",
      " 105 f105    float64\n",
      " 106 f106    float64\n",
      " 107 f107    float64\n",
      " 108 f108    float64\n",
      " 109 f109    float64\n",
      " 110 f110    float64\n",
      " 111 f111    float64\n",
      " 112 f112    float64\n",
      " 113 f113    float64\n",
      " 114 f114    float64\n",
      " 115 f115    float64\n",
      " 116 f116    float64\n",
      " 117 f117    float64\n",
      " 118 f118    float64\n",
      " 119 claim   int64  \n",
      "dtypes: float64(118), int64(2)\n",
      "memory usage: 877.0 MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#Are there any missing values \r\n",
    "play_train.isna().values.any() "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#Number of missing values by each column in training data\r\n",
    "play_train.isna().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "id           0\n",
       "f1       15247\n",
       "f2       15190\n",
       "f3       15491\n",
       "f4       15560\n",
       "         ...  \n",
       "f115     15559\n",
       "f116     15589\n",
       "f117     15407\n",
       "f118     15212\n",
       "claim        0\n",
       "Length: 120, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#Number of missing values by column in test data\r\n",
    "play_test.isna().values.any()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "play_test.isna().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "id         0\n",
       "f1      7812\n",
       "f2      7891\n",
       "f3      7795\n",
       "f4      7733\n",
       "        ... \n",
       "f114    7942\n",
       "f115    7977\n",
       "f116    8083\n",
       "f117    7763\n",
       "f118    7885\n",
       "Length: 119, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#Seperating the target from the training data \r\n",
    "X = play_train.drop(['claim'], axis =1)\r\n",
    "y = play_train['claim']\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#Splitting training data into training and validation set \r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 0)  \r\n",
    "print(X_train.shape, X_val.shape, y_train.shape,y_val.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(766335, 119) (191584, 119) (766335,) (191584,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#Preparing the test data \r\n",
    "X_test = play_test\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "#Imputting missing values in training data \r\n",
    "from sklearn.impute import SimpleImputer \r\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy= 'mean')\r\n",
    "imputer.fit(X_train)\r\n",
    "X_train_imputed = imputer.transform(X_train)\r\n",
    "X_train_imputed_df = pd.DataFrame(X_train_imputed, columns=X_train.columns)\r\n",
    "print(X_train_imputed_df.isna().any())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "id      False\n",
      "f1      False\n",
      "f2      False\n",
      "f3      False\n",
      "f4      False\n",
      "        ...  \n",
      "f114    False\n",
      "f115    False\n",
      "f116    False\n",
      "f117    False\n",
      "f118    False\n",
      "Length: 119, dtype: bool\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "#Imputing missing values in validation and test data\r\n",
    "X_val_imputed_df = pd.DataFrame(imputer.transform(X_val), columns=X_val.columns)\r\n",
    "X_test_imputed_df = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\r\n",
    "print(X_val_imputed_df.isna().any())\r\n",
    "print(X_test_imputed_df.isna().any())\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "id      False\n",
      "f1      False\n",
      "f2      False\n",
      "f3      False\n",
      "f4      False\n",
      "        ...  \n",
      "f114    False\n",
      "f115    False\n",
      "f116    False\n",
      "f117    False\n",
      "f118    False\n",
      "Length: 119, dtype: bool\n",
      "id      False\n",
      "f1      False\n",
      "f2      False\n",
      "f3      False\n",
      "f4      False\n",
      "        ...  \n",
      "f114    False\n",
      "f115    False\n",
      "f116    False\n",
      "f117    False\n",
      "f118    False\n",
      "Length: 119, dtype: bool\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "#Fitting a Random Forest Classifier \r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\r\n",
    "model.fit(X_train_imputed_df, y_train)\r\n",
    "#Making predictions using validation data\r\n",
    "y_predict = model.predict(X_valid_imputed_df)\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_valid_imputed_df' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-883dd25dac99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_imputed_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Making predictions using validation data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0my_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid_imputed_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_valid_imputed_df' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn import metrics \r\n",
    "print('Accuracy: ', metrics.accuracy_score(y_predict, y_val))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy:  0.5477701686988475\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Fitting an xg boost classifier \r\n",
    "import xgboost as xgb\r\n",
    "model_xgb = xgb.XGBClassifier(n_estimators = 100, max_depth = 5) \r\n",
    "model_xgb.fit(X_train, y_train)\r\n",
    "#Naking preditions\r\n",
    "y_predict_xgb = model_xgb.predict(X_val)\r\n",
    "#model accuracy \r\n",
    "print('Accuracy:', metrics.accuracy_score(y_predict_xgb, y_val))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Edson Kambeu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[23:44:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.7384384917320862\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "a297a2b994ae0802deeed98fd952081b69dcadf1219eb73ad23176f394cf2644"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}